{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "\n",
    "## Description\n",
    "Brief description of what this notebook does and the business problem it solves.\n",
    "\n",
    "## Learning Objectives\n",
    "- Objective 1: What you will learn or accomplish\n",
    "- Objective 2: Specific skill or technique\n",
    "- Objective 3: Business insight to gain\n",
    "\n",
    "## Data Sources\n",
    "- Source 1: [Description and link if applicable]\n",
    "- Source 2: [Description and link if applicable]\n",
    "- Source 3: [Description and link if applicable]\n",
    "\n",
    "## Business Context\n",
    "Explanation of the business problem and why this analysis matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Custom imports for this project\n",
    "# from utils.data_cleaning import clean_data\n",
    "# from utils.visualization import create_dashboard\n",
    "\n",
    "# CONFIGURATION\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization setup\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom colors for business branding\n",
    "BUSINESS_COLORS = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D', '#3B1F2B']\n",
    "sns.set_palette(BUSINESS_COLORS)\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Load and validate data\n",
    "def load_data(file_path, description=\"\"):\n",
    "    \"\"\"\n",
    "    Load data from file with basic validation\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to data file\n",
    "        description (str): Description of the dataset\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded data\n",
    "    \"\"\"\n",
    "    print(f\"üìÇ Loading {description}...\")\n",
    "    \n",
    "    # Determine file type and load accordingly\n",
    "    if file_path.endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.endswith('.xlsx'):\n",
    "        df = pd.read_excel(file_path)\n",
    "    elif file_path.endswith('.json'):\n",
    "        df = pd.read_json(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "    return df\n",
    "\n",
    "# Load your datasets here\n",
    "# Example:\n",
    "# sales_data = load_data('data/raw/sales.csv', 'Sales Transactions')\n",
    "# customer_data = load_data('data/raw/customers.csv', 'Customer Information')\n",
    "\n",
    "# For demonstration - create sample data\n",
    "print(\"üîß Creating sample data for template...\")\n",
    "np.random.seed(42)\n",
    "\n",
    "sample_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2024-01-01', periods=100, freq='D'),\n",
    "    'product': np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor'], 100),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100),\n",
    "    'sales_amount': np.random.normal(1000, 300, 100),\n",
    "    'units_sold': np.random.randint(1, 50, 100),\n",
    "    'customer_type': np.random.choice(['New', 'Returning', 'VIP'], 100)\n",
    "})\n",
    "\n",
    "sales_data = sample_data\n",
    "print(\"üìä Sample data created for demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Generate data overview\n",
    "def explore_data(df, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Generate comprehensive data exploration summary\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"üìä {dataset_name} EXPLORATION\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Basic information\n",
    "    print(f\"\\nüìã BASIC INFORMATION:\")\n",
    "    print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    \n",
    "    # Data types\n",
    "    print(f\"\\nüîß DATA TYPES:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Missing values\n",
    "    print(f\"\\n‚ùì MISSING VALUES:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_percent = (missing_data / len(df)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing_data,\n",
    "        'Missing %': missing_percent\n",
    "    })\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"\\nüìà NUMERICAL SUMMARY:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Categorical summary\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\nüè∑Ô∏è CATEGORICAL SUMMARY:\")\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(df[col].value_counts().head())\n",
    "\n",
    "# Explore the data\n",
    "explore_data(sales_data, \"Sales Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Create exploratory visualizations\n",
    "def create_exploratory_plots(df):\n",
    "    \"\"\"\n",
    "    Create a set of exploratory visualizations\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('Exploratory Data Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Distribution of numerical variable\n",
    "    if 'sales_amount' in df.columns:\n",
    "        axes[0,0].hist(df['sales_amount'], bins=20, color=BUSINESS_COLORS[0], alpha=0.7)\n",
    "        axes[0,0].set_title('Distribution of Sales Amount')\n",
    "        axes[0,0].set_xlabel('Sales Amount ($)')\n",
    "        axes[0,0].set_ylabel('Frequency')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Categorical variable distribution\n",
    "    if 'product' in df.columns:\n",
    "        product_counts = df['product'].value_counts()\n",
    "        axes[0,1].bar(product_counts.index, product_counts.values, color=BUSINESS_COLORS[1])\n",
    "        axes[0,1].set_title('Sales by Product')\n",
    "        axes[0,1].set_xlabel('Product')\n",
    "        axes[0,1].set_ylabel('Number of Sales')\n",
    "        axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 3: Time series trend (if date column exists)\n",
    "    if 'date' in df.columns:\n",
    "        daily_sales = df.groupby('date')['sales_amount'].sum()\n",
    "        axes[1,0].plot(daily_sales.index, daily_sales.values, \n",
    "                      color=BUSINESS_COLORS[2], linewidth=2, marker='o')\n",
    "        axes[1,0].set_title('Daily Sales Trend')\n",
    "        axes[1,0].set_xlabel('Date')\n",
    "        axes[1,0].set_ylabel('Total Sales ($)')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 4: Box plot by category\n",
    "    if 'region' in df.columns and 'sales_amount' in df.columns:\n",
    "        df.boxplot(column='sales_amount', by='region', ax=axes[1,1], \n",
    "                  boxprops=dict(color=BUSINESS_COLORS[3]))\n",
    "        axes[1,1].set_title('Sales Distribution by Region')\n",
    "        axes[1,1].set_xlabel('Region')\n",
    "        axes[1,1].set_ylabel('Sales Amount ($)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "create_exploratory_plots(sales_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Data cleaning pipeline\n",
    "def clean_data(df, config=None):\n",
    "    \"\"\"\n",
    "    Clean and preprocess the dataset\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Raw data\n",
    "        config (dict): Cleaning configuration\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned data\n",
    "    \"\"\"\n",
    "    print(\"üßπ Starting data cleaning...\")\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # 1. Handle missing values\n",
    "    missing_before = df_clean.isnull().sum().sum()\n",
    "    \n",
    "    # Example cleaning operations\n",
    "    # Fill numerical missing values with median\n",
    "    numerical_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        if df_clean[col].isnull().any():\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "    \n",
    "    # Fill categorical missing values with mode\n",
    "    categorical_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        if df_clean[col].isnull().any():\n",
    "            df_clean[col].fillna(df_clean[col].mode()[0], inplace=True)\n",
    "    \n",
    "    missing_after = df_clean.isnull().sum().sum()\n",
    "    print(f\"‚úÖ Missing values handled: {missing_before} ‚Üí {missing_after}\")\n",
    "    \n",
    "    # 2. Remove duplicates\n",
    "    duplicates_before = df_clean.duplicated().sum()\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    duplicates_after = df_clean.duplicated().sum()\n",
    "    print(f\"‚úÖ Duplicates removed: {duplicates_before} ‚Üí {duplicates_after}\")\n",
    "    \n",
    "    # 3. Data type conversions\n",
    "    if 'date' in df_clean.columns:\n",
    "        df_clean['date'] = pd.to_datetime(df_clean['date'])\n",
    "        print(\"‚úÖ Date columns converted\")\n",
    "    \n",
    "    # 4. Outlier detection (example)\n",
    "    if 'sales_amount' in df_clean.columns:\n",
    "        Q1 = df_clean['sales_amount'].quantile(0.25)\n",
    "        Q3 = df_clean['sales_amount'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_count = ((df_clean['sales_amount'] < (Q1 - 1.5 * IQR)) | \n",
    "                        (df_clean['sales_amount'] > (Q3 + 1.5 * IQR))).sum()\n",
    "        print(f\"üìä Outliers detected in sales_amount: {outlier_count}\")\n",
    "    \n",
    "    print(f\"üéØ Cleaning complete. Final shape: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "cleaned_data = clean_data(sales_data)\n",
    "\n",
    "# Verify cleaning\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING VERIFICATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Missing values: {cleaned_data.isnull().sum().sum()}\")\n",
    "print(f\"Duplicates: {cleaned_data.duplicated().sum()}\")\n",
    "print(f\"Data types:\\n{cleaned_data.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Create new features\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create new features for analysis\n",
    "    \"\"\"\n",
    "    print(\"üîß Engineering features...\")\n",
    "    df_engineered = df.copy()\n",
    "    \n",
    "    # Example feature engineering operations\n",
    "    \n",
    "    # 1. Time-based features\n",
    "    if 'date' in df_engineered.columns:\n",
    "        df_engineered['year'] = df_engineered['date'].dt.year\n",
    "        df_engineered['month'] = df_engineered['date'].dt.month\n",
    "        df_engineered['day_of_week'] = df_engineered['date'].dt.day_name()\n",
    "        df_engineered['quarter'] = df_engineered['date'].dt.quarter\n",
    "        print(\"‚úÖ Time-based features created\")\n",
    "    \n",
    "    # 2. Business metrics\n",
    "    if all(col in df_engineered.columns for col in ['sales_amount', 'units_sold']):\n",
    "        df_engineered['average_price'] = df_engineered['sales_amount'] / df_engineered['units_sold']\n",
    "        df_engineered['price_category'] = pd.cut(df_engineered['average_price'], \n",
    "                                               bins=3, \n",
    "                                               labels=['Low', 'Medium', 'High'])\n",
    "        print(\"‚úÖ Business metrics calculated\")\n",
    "    \n",
    "    # 3. Aggregation features\n",
    "    if 'product' in df_engineered.columns and 'sales_amount' in df_engineered.columns:\n",
    "        product_stats = df_engineered.groupby('product')['sales_amount'].agg(['mean', 'std']).reset_index()\n",
    "        product_stats.columns = ['product', 'product_avg_sales', 'product_std_sales']\n",
    "        df_engineered = df_engineered.merge(product_stats, on='product', how='left')\n",
    "        df_engineered['sales_deviation'] = (df_engineered['sales_amount'] - df_engineered['product_avg_sales']) / df_engineered['product_std_sales']\n",
    "        print(\"‚úÖ Aggregation features created\")\n",
    "    \n",
    "    print(f\"‚úÖ Feature engineering complete. New shape: {df_engineered.shape}\")\n",
    "    print(f\"New columns: {list(set(df_engineered.columns) - set(df.columns))}\")\n",
    "    \n",
    "    return df_engineered\n",
    "\n",
    "# Engineer features\n",
    "final_data = engineer_features(cleaned_data)\n",
    "\n",
    "# Show new features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE ENGINEERING RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(final_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis and Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Perform business analysis\n",
    "def perform_business_analysis(df):\n",
    "    \"\"\"\n",
    "    Perform comprehensive business analysis\n",
    "    \"\"\"\n",
    "    print(\"üìà Performing business analysis...\")\n",
    "    \n",
    "    insights = {}\n",
    "    \n",
    "    # 1. Overall business metrics\n",
    "    if 'sales_amount' in df.columns:\n",
    "        insights['total_revenue'] = df['sales_amount'].sum()\n",
    "        insights['average_sale'] = df['sales_amount'].mean()\n",
    "        insights['total_transactions'] = len(df)\n",
    "    \n",
    "    # 2. Performance by category\n",
    "    if 'product' in df.columns and 'sales_amount' in df.columns:\n",
    "        product_performance = df.groupby('product').agg({\n",
    "            'sales_amount': ['sum', 'mean', 'count'],\n",
    "            'units_sold': 'sum' if 'units_sold' in df.columns else 'count'\n",
    "        }).round(2)\n",
    "        insights['product_performance'] = product_performance\n",
    "    \n",
    "    # 3. Time-based analysis\n",
    "    if 'month' in df.columns and 'sales_amount' in df.columns:\n",
    "        monthly_sales = df.groupby('month')['sales_amount'].sum()\n",
    "        insights['monthly_sales'] = monthly_sales\n",
    "    \n",
    "    # 4. Regional analysis\n",
    "    if 'region' in df.columns and 'sales_amount' in df.columns:\n",
    "        regional_performance = df.groupby('region')['sales_amount'].agg(['sum', 'mean', 'count'])\n",
    "        insights['regional_performance'] = regional_performance\n",
    "    \n",
    "    print(\"‚úÖ Business analysis complete\")\n",
    "    return insights\n",
    "\n",
    "# Perform analysis\n",
    "business_insights = perform_business_analysis(final_data)\n",
    "\n",
    "# Display key insights\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"KEY BUSINESS INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if 'total_revenue' in business_insights:\n",
    "    print(f\"üí∞ Total Revenue: ${business_insights['total_revenue']:,.2f}\")\n",
    "    print(f\"üìä Average Sale: ${business_insights['average_sale']:,.2f}\")\n",
    "    print(f\"üõí Total Transactions: {business_insights['total_transactions']:,}\")\n",
    "\n",
    "if 'product_performance' in business_insights:\n",
    "    print(f\"\\nüèÜ PRODUCT PERFORMANCE:\")\n",
    "    print(business_insights['product_performance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Create advanced business visualizations\n",
    "def create_business_dashboard(df, insights):\n",
    "    \"\"\"\n",
    "    Create a comprehensive business dashboard\n",
    "    \"\"\"\n",
    "    print(\"üìä Creating business dashboard...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Business Performance Dashboard', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: Revenue by Product\n",
    "    if 'product_performance' in insights:\n",
    "        product_revenue = insights['product_performance'][('sales_amount', 'sum')]\n",
    "        axes[0,0].bar(product_revenue.index, product_revenue.values, color=BUSINESS_COLORS)\n",
    "        axes[0,0].set_title('Total Revenue by Product', fontweight='bold')\n",
    "        axes[0,0].set_ylabel('Revenue ($)')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(product_revenue.values):\n",
    "            axes[0,0].text(i, v, f'${v:,.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Monthly Sales Trend\n",
    "    if 'monthly_sales' in insights:\n",
    "        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        monthly_data = insights['monthly_sales']\n",
    "        axes[0,1].plot(range(1, len(monthly_data) + 1), monthly_data.values, \n",
    "                      marker='o', linewidth=2, color=BUSINESS_COLORS[1])\n",
    "        axes[0,1].set_title('Monthly Sales Trend', fontweight='bold')\n",
    "        axes[0,1].set_xlabel('Month')\n",
    "        axes[0,1].set_ylabel('Sales ($)')\n",
    "        axes[0,1].set_xticks(range(1, len(monthly_data) + 1))\n",
    "        axes[0,1].set_xticklabels(months[:len(monthly_data)])\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Regional Performance\n",
    "    if 'regional_performance' in insights:\n",
    "        regional_avg = insights['regional_performance'][('sales_amount', 'mean')]\n",
    "        axes[1,0].pie(regional_avg.values, labels=regional_avg.index, autopct='%1.1f%%',\n",
    "                     colors=BUSINESS_COLORS)\n",
    "        axes[1,0].set_title('Average Sales by Region', fontweight='bold')\n",
    "    \n",
    "    # Plot 4: Sales Distribution\n",
    "    if 'sales_amount' in df.columns:\n",
    "        axes[1,1].hist(df['sales_amount'], bins=20, color=BUSINESS_COLORS[3], alpha=0.7, edgecolor='black')\n",
    "        axes[1,1].axvline(df['sales_amount'].mean(), color='red', linestyle='--', linewidth=2, \n",
    "                         label=f'Mean: ${df[\\\"sales_amount\\\"].mean():.0f}')\n",
    "        axes[1,1].set_title('Sales Amount Distribution', fontweight='bold')\n",
    "        axes[1,1].set_xlabel('Sales Amount ($)')\n",
    "        axes[1,1].set_ylabel('Frequency')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Business dashboard created\")\n",
    "\n",
    "# Create dashboard\n",
    "create_business_dashboard(final_data, business_insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Insights and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Generate executive summary\n",
    "def generate_executive_summary(insights, df):\n",
    "    \"\"\"\n",
    "    Generate an executive summary of findings\n",
    "    \"\"\"\n",
    "    print(\"üìã Generating executive summary...\")\n",
    "    \n",
    "    summary = f\"\"\"\n",
    "    \n",
    "{'='*60}\n",
    "EXECUTIVE SUMMARY\"\n",
    "{'='*60}\n",
    "\n",
    "üìà OVERVIEW:\"\n",
    "‚Ä¢ Total Revenue: ${insights.get('total_revenue', 0):,.2f}\"\n",
    "‚Ä¢ Average Transaction: ${insights.get('average_sale', 0):,.2f}\"\n",
    "‚Ä¢ Total Transactions: {insights.get('total_transactions', 0):,}\"\n",
    "‚Ä¢ Analysis Period: {df['date'].min().strftime('%Y-%m-%d') if 'date' in df.columns else 'N/A'} to {df['date'].max().strftime('%Y-%m-%d') if 'date' in df.columns else 'N/A'}\"\n",
    "‚Ä¢ Data Quality: {len(df)} records after cleaning\"\n",
    "\n",
    "üèÜ TOP PERFORMERS:\"\n",
    "\"\"\n",
    "    \n",
    "    if 'product_performance' in insights:\n",
    "        product_revenue = insights['product_performance'][('sales_amount', 'sum')]\n",
    "        top_product = product_revenue.idxmax()\n",
    "        top_revenue = product_revenue.max()\n",
    "        summary += f\"‚Ä¢ Best Product: {top_product} (${top_revenue:,.2f})\\n\"\n",
    "    \n",
    "    if 'regional_performance' in insights:\n",
    "        regional_avg = insights['regional_performance'][('sales_amount', 'mean')]\n",
    "        top_region = regional_avg.idxmax()\n",
    "        top_region_avg = regional_avg.max()\n",
    "        summary += f\"‚Ä¢ Top Region: {top_region} (${top_region_avg:,.2f} average sale)\\n\"\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "\n",
    "üí° KEY INSIGHTS:\"\n",
    "\"\"\n",
    "    \n",
    "    # Add dynamic insights based on analysis\n",
    "    if 'sales_amount' in df.columns:\n",
    "        cv = df['sales_amount'].std() / df['sales_amount'].mean()\n",
    "        summary += f\"‚Ä¢ Sales variability: {cv:.2%} coefficient of variation\\n\"\n",
    "    \n",
    "    if 'monthly_sales' in insights:\n",
    "        monthly_growth = (insights['monthly_sales'].iloc[-1] - insights['monthly_sales'].iloc[0]) / insights['monthly_sales'].iloc[0]\n",
    "        summary += f\"‚Ä¢ Monthly growth trend: {monthly_growth:.2%}\\n\"\n",
    "    \n",
    "    summary += f\"\"\"\n",
    "\n",
    "üéØ RECOMMENDATIONS:\"\n",
    "‚Ä¢ Consider scaling successful products/regions\"\n",
    "‚Ä¢ Investigate underperforming areas for improvement\"\n",
    "‚Ä¢ Continue monitoring key metrics regularly\"\n",
    "‚Ä¢ Explore customer segmentation for targeted marketing\"\n",
    "{'='*60}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(summary)\n",
    "    return summary\n",
    "\n",
    "# Generate summary\n",
    "executive_summary = generate_executive_summary(business_insights, final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: Export results and artifacts\n",
    "def export_results(df, insights, summary, export_path='output/'):\n",
    "    \"\"\"\n",
    "    Export analysis results and artifacts\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import json\n",
    "    \n",
    "    print(\"üíæ Exporting results...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(export_path, exist_ok=True)\n",
    "    \n",
    "    # 1. Export cleaned data\n",
    "    df.to_csv(f'{export_path}cleaned_data.csv', index=False)\n",
    "    print(f\"‚úÖ Cleaned data exported to {export_path}cleaned_data.csv\")\n",
    "    \n",
    "    # 2. Export insights as JSON\n",
    "    insights_exportable = {}\n",
    "    for key, value in insights.items():\n",
    "        if isinstance(value, pd.DataFrame):\n",
    "            insights_exportable[key] = value.to_dict()\n",
    "        elif isinstance(value, pd.Series):\n",
    "            insights_exportable[key] = value.to_dict()\n",
    "        else:\n",
    "            insights_exportable[key] = value\n",
    "    \n",
    "    with open(f'{export_path}business_insights.json', 'w') as f:\n",
    "        json.dump(insights_exportable, f, indent=2, default=str)\n",
    "    print(f\"‚úÖ Insights exported to {export_path}business_insights.json\")\n",
    "    \n",
    "    # 3. Export executive summary\n",
    "    with open(f'{export_path}executive_summary.txt', 'w') as f:\n",
    "        f.write(summary)\n",
    "    print(f\"‚úÖ Executive summary exported to {export_path}executive_summary.txt\")\n",
    "    \n",
    "    # 4. Save final visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    if 'product_performance' in insights:\n",
    "        product_revenue = insights['product_performance'][('sales_amount', 'sum')]\n",
    "        plt.bar(product_revenue.index, product_revenue.values, color=BUSINESS_COLORS)\n",
    "        plt.title('Product Revenue Performance', fontweight='bold')\n",
    "        plt.ylabel('Revenue ($)')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{export_path}product_performance.png', dpi=300, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Visualization saved to {export_path}product_performance.png\")\n",
    "    \n",
    "    print(f\"üéâ All results exported to {export_path} directory\")\n",
    "\n",
    "# Export results (commented out to prevent file creation in template)\n",
    "# export_results(final_data, business_insights, executive_summary, 'output/')\n",
    "print(\"üí° Export functionality ready - uncomment the line above to export results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Next Steps and Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Enhancements\n",
    "\n",
    "**Data Enhancements:**\n",
    "- Incorporate external data sources (economic indicators, weather data)\n",
    "- Add customer demographic information\n",
    "- Include competitor pricing data\n",
    "\n",
    "**Analytical Improvements:**\n",
    "- Implement machine learning for sales forecasting\n",
    "- Add customer lifetime value calculations\n",
    "- Create segmentation analysis\n",
    "- Develop A/B testing framework\n",
    "\n",
    "**Technical Improvements:**\n",
    "- Automate data pipeline with Apache Airflow\n",
    "- Create interactive dashboard with Plotly Dash/Streamlit\n",
    "- Implement database integration\n",
    "- Add unit tests for data validation\n",
    "\n",
    "**Business Applications:**\n",
    "- Real-time monitoring system\n",
    "- Automated reporting\n",
    "- Predictive maintenance alerts\n",
    "- Customer churn prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. References and Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/)\n",
    "- [Matplotlib Documentation](https://matplotlib.org/stable/contents.html)\n",
    "- [Seaborn Documentation](https://seaborn.pydata.org/)\n",
    "\n",
    "### Best Practices\n",
    "- Follow PEP 8 style guide\n",
    "- Use version control (Git)\n",
    "- Document your code and assumptions\n",
    "- Validate data quality at each step\n",
    "\n",
    "### Related Projects\n",
    "- [Data Cleaning Pipeline](link-to-project)\n",
    "- [Dashboard Development](link-to-project)\n",
    "- [Machine Learning Models](link-to-project)\n",
    "\n",
    "---\n",
    "\n",
    "**Notebook Created:** [Date]\n",
    "**Last Updated:** [Date]\n",
    "**Author:** [Your Name]\n",
    "**Version:** 1.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 }
}